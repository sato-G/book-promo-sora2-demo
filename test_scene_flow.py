#!/usr/bin/env python3
"""
ã‚·ãƒ¼ãƒ³åˆ†å‰²â†’Sora2ç”Ÿæˆâ†’çµåˆã®ãƒ•ãƒ«ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ

test_sora2.pyã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å³å¯†ã«å¾“ã†
3ã‚·ãƒ¼ãƒ³ä½œæˆ â†’ çµåˆ
"""

import os
import sys
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))
from backend import video_composer

load_dotenv()

# ãƒ†ã‚¹ãƒˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ3ã‚·ãƒ¼ãƒ³ã€å„50æ–‡å­—å‰å¾Œã€æ¶ç©ºã®å†…å®¹ï¼‰
narrations = [
    "ã“ã®ç‰©èªã¯ã€ä¸€äººã®å°‘å¹´ãŒå†’é™ºã«å‡ºã‚‹è©±ã§ã™ã€‚å½¼ã¯å‹‡æ°—ã‚’æŒã£ã¦ã€æœªçŸ¥ã®ä¸–ç•Œã¸ã¨æ—…ç«‹ã¡ã¾ã™ã€‚",  # Test 2æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³
    "å›°é›£ãªé“ã®ã‚Šã®ä¸­ã§ã€å°‘å¹´ã¯å¤šãã®ä»²é–“ã¨å‡ºä¼šã„ã€å…±ã«æˆé•·ã—ã¦ã„ãã¾ã™ã€‚çµ†ã®åŠ›ãŒè©¦ã•ã‚Œã‚‹ã€‚",
    "æœ€å¾Œã®è©¦ç·´ã‚’ä¹—ã‚Šè¶ŠãˆãŸæ™‚ã€å°‘å¹´ã¯çœŸã®ãƒ’ãƒ¼ãƒ­ãƒ¼ã¸ã¨å¤‰ã‚ã‚‹ã€‚æ„Ÿå‹•ã®å†’é™ºç‰©èªãŒã“ã“ã«å®Œçµã™ã‚‹ã€‚"
]

def generate_scene_video(narration, scene_num, output_dir):
    """test_sora2.py Test 2ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å³å¯†ã«ä½¿ç”¨"""
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

    print(f"\n{'='*60}")
    print(f"ã‚·ãƒ¼ãƒ³ {scene_num}: {narration} ({len(narration)}æ–‡å­—)")
    print(f"{'='*60}")

    # test_sora2.py Test 2ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å³å¯†ã«ã‚³ãƒ”ãƒ¼
    prompt = f"""Book promotional video, 12 seconds, cinematic style, 16:9.
Japanese voice-over with background music.

Voice-over (Japanese): {narration}"""

    print(f"Prompt:\n{prompt}\n")
    print("ğŸ¬ Sora2ã§ç”Ÿæˆä¸­...")

    try:
        video = client.videos.create_and_poll(
            model="sora-2",
            prompt=prompt,
            seconds="12",
            size="1280x720"
        )

        print(f"âœ“ ç”Ÿæˆå®Œäº† (Video ID: {video.id})")

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        print("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        content = client.videos.download_content(video.id)

        output_path = output_dir / f"scene_{scene_num}.mp4"
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "wb") as f:
            for chunk in content.iter_bytes():
                f.write(chunk)

        print(f"âœ“ ä¿å­˜: {output_path}")
        return output_path

    except Exception as e:
        print(f"âœ— ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    print("="*60)
    print("ã‚·ãƒ¼ãƒ³åˆ†å‰²â†’Sora2ç”Ÿæˆâ†’çµåˆ ãƒ•ãƒ«ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ")
    print("="*60)
    print(f"\nã‚·ãƒ¼ãƒ³æ•°: {len(narrations)}")
    print(f"åˆè¨ˆæ™‚é–“: {len(narrations) * 12}ç§’")
    print(f"åˆè¨ˆæ–‡å­—æ•°: {sum(len(n) for n in narrations)}æ–‡å­—")

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = Path("test_scene_output")
    output_dir.mkdir(exist_ok=True)

    # å„ã‚·ãƒ¼ãƒ³ã‚’ç”Ÿæˆ
    scene_videos = []

    for i, narration in enumerate(narrations, 1):
        video_path = generate_scene_video(narration, i, output_dir)
        if video_path:
            scene_videos.append(video_path)
        else:
            print(f"âœ— ã‚·ãƒ¼ãƒ³ {i} ã®ç”Ÿæˆã«å¤±æ•—")
            return

    print(f"\nâœ… å…¨{len(scene_videos)}ã‚·ãƒ¼ãƒ³ã®ç”Ÿæˆå®Œäº†ï¼")

    # å‹•ç”»ã‚’çµåˆ
    print("\n" + "="*60)
    print("å‹•ç”»çµåˆä¸­...")
    print("="*60)

    try:
        final_video = video_composer.concatenate_videos(
            scene_videos,
            output_file=output_dir / "final_combined.mp4"
        )

        print(f"\nğŸ‰ å®Œæˆï¼")
        print(f"ğŸ“¹ æœ€çµ‚å‹•ç”»: {final_video}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        size_mb = final_video.stat().st_size / (1024 * 1024)
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size_mb:.2f} MB")

    except Exception as e:
        print(f"âœ— çµåˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
